---
title: "[AI ë§í‰ ëŒ€íšŒ] ì°¸ì—¬ê¸° #11: 3ì£¼ì°¨(3) - GRPO í•™ìŠµ êµ¬í˜„"
date: 2025-07-25 20:00:00 +09:00
categories: [2025_ë§í‰, NLP, AI]
tags: [ë§í‰ëŒ€íšŒ, GRPO, RL, TRL, LoRA, InferenceCallback, ExactMatch, ROUGE, BERTScore]
toc: true
math: true
image:
  path: /assets/img/for_post/MalPyeong/week3_rl_impl.png
  alt: "GRPO êµ¬í˜„"
---

# #11. GRPO í•™ìŠµ êµ¬í˜„

> ì €ë²ˆì— **ê°œë…ê³¼ ë³´ìƒ ì•„ì´ë””ì–´**ë¥¼ ì •ë¦¬í–ˆë‹¤ë©´, ì´ë²ˆ í¸ì€ ì‹¤ì œ êµ¬í˜„ì´ë‹¤. 

>íŒ€ì›ë¶„ì˜ ì¡°ì–¸ì— ë”°ë¼ ì½œë°±(CallBack)ì„ í†µí•´ **ì €ì¥ ì‹œì ë§ˆë‹¤ ìë™ ê²€ì¦ ì¶”ë¡  â†’ JSON ì €ì¥ â†’ í•œ ë²ˆì— ìŠ¤ì½”ì–´ë§ â†’ ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ì„ íƒ** íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í–ˆë‹¤.

---

## 1) ë°ì´í„°/í”„ë¡¬í”„íŠ¸ íŒŒì´í”„ë¼ì¸

- **CustomDataset**ì€ ì…ë ¥ JSONì—ì„œ `question`ê³¼ `answer`ë¥¼ ì½ê³ , ì§€ì‹œë¬¸(`instruct`)ê³¼ **few-shot ì˜ˆì‹œ**ë¥¼ í•©ì³ ì¸í¼ëŸ°ìŠ¤ìš© ì…ë ¥ì„ êµ¬ì„±í•œë‹¤.  
- few-shotì€ **ìœ í˜•ë³„ ìƒ˜í”Œë§(Category_FewShotGenerater)** ì„ ì‚¬ìš©í•´ ì„ íƒí˜•/êµì •í˜•ì„ êµ¬ë¶„í•´ ë„£ì—ˆë‹¤.

```python
# ë°ì´í„°ì…‹/ì§€ì‹œë¬¸ ì¤€ë¹„ (ìš”ì•½)
tokenizer = AutoTokenizer.from_pretrained(args.model_name)
few_shot = Category_FewShotGenerater(args.few_shot_data_path, num_few_shot=args.num_few_shot_data)

with open(args.instruct_path, 'r', encoding='utf-8') as f:
    instruct = json.load(f)

train_dataset = CustomDataset(args.train_data_path, tokenizer, instruct, few_shot_generater=few_shot)
eval_dataset  = CustomDataset(args.eval_data_path,  tokenizer, instruct, few_shot_generater=few_shot)
```

---

## 2) ë³´ìƒ í•¨ìˆ˜(Reward) êµ¬ì„±

ëŒ€íšŒ ì§€í‘œë¥¼ ê·¸ëŒ€ë¡œ ë³´ìƒìœ¼ë¡œ ì“´ë‹¤. **Format(â€œ...ì´/ê°€ ì˜³ë‹¤.â€), EM, ROUGEâ€‘1, BERTScore** ë¥¼ ì¡°í•©í•œë‹¤.

```python
def multi_reward(prompts, completions, references=None, **kwargs):
    r_bert  = BERTScore_reward_fn(prompts, completions, references)
    r_em    = EM_reward_fn(prompts, completions, references)
    r_form  = format_reward_fn(prompts, completions, references)
    r_rouge = ROUGE_1_reward_fn(prompts, completions, references)
    # ì¡°í•©: (BERT + EM + (Format + 3*ROUGE)/2) / 3
    return [(b + e + (f + 3*r)/2) / 3 for b, e, f, r in zip(r_bert, r_em, r_form, r_rouge)]
```

> í¬ë§· ë³´ìƒì€ ì •ë‹µ ë¬¸ì¥ í˜•ì‹ì„ ì •ê·œì‹ìœ¼ë¡œ ì²´í¬í•˜ê³ , EMì€ `ì •ë‹µë¬¸ì¥` ì¼ì¹˜(ì—¬ëŸ¬ í—ˆìš© ì •ë‹µ `#` ë¶„ë¦¬)ë¡œ 0/1 ìŠ¤ì½”ì–´,  
> ROUGEâ€‘1/BERTScoreëŠ” **ì´ìœ (reason)** ë¶€ë¶„ì˜ ìœ ì‚¬ë„ë¥¼ í‰ê°€í•œë‹¤.

---

## 3) GRPO ì„¤ì •ê³¼ ì½œë°± ë“±ë¡

í•™ìŠµì€ **TRLì˜ `GRPOTrainer`** ë¥¼ ì‚¬ìš©í•˜ê³ , ì €ì¥ íƒ€ì´ë°ë§ˆë‹¤ 2ê°œì˜ ì½œë°±ì´ ë™ì‘í•œë‹¤.

- **LoraSaveCallback**: LoRA ì–´ëŒ‘í„°ë¥¼ `output_dir/epoch_{E}`ì— ì €ì¥
- **InferenceCallback**: ë°©ê¸ˆ ì €ì¥ëœ ê°€ì¤‘ì¹˜ë¥¼ ì¦‰ì‹œ ë¡œë“œí•´ **ê²€ì¦ì…‹ì— ì¶”ë¡ ** â†’ `inference_epoch{E}.json` ì €ì¥

```python
grpo_config = GRPOConfig(
    num_generations=args.num_generations,
    output_dir=args.output_dir,
    num_train_epochs=args.num_train_epochs,
    per_device_train_batch_size=args.per_device_train_batch_size,
    gradient_accumulation_steps=args.gradient_accumulation_steps,
    learning_rate=args.learning_rate,
    logging_steps=args.logging_steps,
    save_strategy=args.save_strategy,    # "epoch" ê¶Œì¥
    eval_strategy=args.eval_strategy,    # "no" ë˜ëŠ” "epoch"
    load_best_model_at_end=False,        # ëª¨ë¸ ì„ íƒì€ ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ë¡œ
    remove_unused_columns=False,
    report_to="wandb"
)

trainer = GRPOTrainer(
    model=base_model,
    args=grpo_config,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    reward_funcs=[multi_reward],
    callbacks=[LoraSaveCallback(), inference_cb]  # ì•„ë˜ InferenceCallback ì°¸ê³ 
)
```

---

## 4) ë©”ëª¨ë¦¬ ê´€ë¦¬

GRPOëŠ” **í•œ í”„ë¡¬í”„íŠ¸ì—ì„œ ì—¬ëŸ¬ ì‘ë‹µì„ ìƒì„±**í•˜ê¸° ë•Œë¬¸ì—, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ `num_generations(G)`ì— **ì„ í˜•**ìœ¼ë¡œ ëŠ˜ì–´ë‚œë‹¤.

**ê¸°í˜¸**
- **B** = `per_device_train_batch_size`
- **G** = `num_generations`
- **A** = `gradient_accumulation_steps`
- **D** = GPU ê°œìˆ˜(world size)

**íš¨ê³¼ì  ë°°ì¹˜ í¬ê¸°**
- í•œ ì˜µí‹°ë§ˆì´ì € ìŠ¤í… ì´ ì‘ë‹µ ìˆ˜: `B Ã— G Ã— A Ã— D`
- í•œ ì˜µí‹°ë§ˆì´ì € ìŠ¤í… í”„ë¡¬í”„íŠ¸ ìˆ˜: `(B Ã· G) Ã— A Ã— D`

> âš ï¸ `B`ëŠ” ë°˜ë“œì‹œ `G`ì˜ ë°°ìˆ˜ì—¬ì•¼ í•œë‹¤.

ì •í•´ì§„ GPU VRAM ì œí•œ(24GB) ë‚´ì—ì„œ í•™ìŠµì„ ëŒë¦¬ëŠë¼ OOMì„ ì •ë§ ë§ì´ ë³¸ê²ƒ ê°™ë‹¤. 
ê·¸ ë•Œë¬¸ì— ì–‘ìí™”ì™€ LoRAë“± ì •ë§ ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ ì ˆì•½ ë°©ì‹ì„ ì ìš©í•˜ë©´ì„œ ë§ì€ê±¸ ë°°ì› ë‹¤. 
í•™ìŠµì„ ëŒë¦¬ë©´ì„œ ì´ ë¶€ë¶„ì„ íŠ¹íˆ ì£¼ì˜í•´ì„œ íŒŒë¼ë¯¸í„° êµ¬ì„±ì„ í–ˆë˜ ê²½í—˜ì´ ìƒê°ë‚˜ ê³µìœ í•´ë³¸ë‹¤.

---

### ğŸ”§ ì–‘ìí™” + LoRA ì ìš© ì½”ë“œ

```python
from transformers import AutoModelForCausalLM, BitsAndBytesConfig
from peft import LoraConfig, get_peft_model

# --- ì–‘ìí™” ì„¤ì • ---
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype="bfloat16",   # bf16 ì—°ì‚°
    bnb_4bit_quant_type="nf4",           # NormalFloat4
    bnb_4bit_use_double_quant=True
)

# --- ëª¨ë¸ ë¡œë“œ (4bit ì–‘ìí™” ì ìš©) ---
base_model = AutoModelForCausalLM.from_pretrained(
    args.model_name,
    quantization_config=bnb_config,
    device_map="auto"
)

# --- LoRA ì„¤ì • ---
lora_config = LoraConfig(
    r=64,
    lora_alpha=16,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# --- LoRA ì–´ëŒ‘í„° ë¶€ì°© ---
model = get_peft_model(base_model, lora_config)
model.print_trainable_parameters()
```

ìœ„ ì½”ë“œì—ì„œ:  
- **ì–‘ìí™”**: 4bit(`nf4`)ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½, ì—°ì‚°ì€ `bfloat16`  
- **LoRA**: q/k/v/o projection ì¸µë§Œ í•™ìŠµ â†’ íŒŒë¼ë¯¸í„°/VRAM ìµœì†Œí™”  

ì´ëŸ° ì„¤ì •ìœ¼ë¡œ 24GB VRAMì—ì„œë„ `K-intelligence/Midm-2.0-Base-Instruct`ê°™ì€ í° ëª¨ë¸ê¹Œì§€ í•™ìŠµì´ ê°€ëŠ¥í–ˆë‹¤.

---

## 5) InferenceCallback: ì €ì¥ ì§í›„, ê²€ì¦ì…‹ ìë™ ì¶”ë¡ 

í•™ìŠµì´ **ì €ì¥(save)** ë  ë•Œë§ˆë‹¤ ë‹¤ìŒì„ ìˆ˜í–‰í•œë‹¤.

1) ê°€ì¥ ìµœê·¼ **LoRA ì–´ëŒ‘í„° í´ë”(ì˜ˆ: `epoch_3/`)** ê²½ë¡œë¥¼ êµ¬ì„±  
2) í•´ë‹¹ ê°€ì¤‘ì¹˜ë¥¼ ë¶™ì—¬ **ê²€ì¦ì…‹ì— generate**  
3) JSON(`..._epoch3.json`) íŒŒì¼ë¡œ ê²°ê³¼ë¥¼ ê¸°ë¡

```python
class InferenceCallback(TrainerCallback):
    def on_save(self, args, state, control, **kwargs):
        epoch = int(state.epoch)
        lora_path = os.path.join(args.output_dir, f"epoch_{epoch}")
        run_inference(
            input_path=args.eval_data_path,
            output_path=args.inference_output_path.replace(".json", f"_epoch{epoch}.json"),
            model_id=args.model_name,
            tokenizer_id=args.model_name,
            lora_weights_path=lora_path,  # ìµœì‹  LoRA
            prompt=instruct["prompt"],
            correction_prompt=instruct["correction_prompt"],
            selection_prompt=instruct["selection_prompt"],
            quant=args.quant_type if args.use_quant else None,
            few_shot_generater=few_shot
        )
```

`run_inference`ëŠ” **ì–‘ìí™” ì˜µì…˜/LoRA ë¶€ì°©/ì¢…ë£Œ í† í° ì„¤ì •** í›„, fewâ€‘shot í”„ë¡¬í”„íŠ¸ë¡œ `generate`ë¥¼ í˜¸ì¶œí•´ **ê° ë¬¸ì œì˜ ë‹µë³€ê³¼ ì •ê·œí™”ëœ ë‹µë³€(normalized)** ì„ JSONìœ¼ë¡œ ì“´ë‹¤.

```python
def run_inference(...):
    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quant_cfg, ...)
    if lora_weights_path:
        model = PeftModel.from_pretrained(model, lora_weights_path)
    model.eval()

    dataset = CustomDataset(input_path, tokenizer, instruct=..., few_shot_generater=few_shot)
    for i in range(len(dataset)):
        outputs = model.generate(...)
        text = tokenizer.decode(outputs[0][input_len:], skip_special_tokens=True)
        text = strip_prefixes_and_normalize(text)
        result[i]["output"] = {"answer": text, "normalized_answer": normalize_quotes(text)}
    json.dump(result, open(output_path, "w"), ensure_ascii=False, indent=4)
```

---

## 6) í•œ ë²ˆì— í‰ê°€í•˜ê³  **ìµœê³  ì²´í¬í¬ì¸íŠ¸ ì„ íƒ**

ì—í­ë§ˆë‹¤ ìƒê¸´ `inference_epoch{E}.json` ë“¤ì„ **í•œ ë””ë ‰í† ë¦¬ì— ëª¨ì•„** ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¡œ í‰ê°€í•œë‹¤.  
í‰ê°€ëŠ” **ROUGEâ€‘1, BERTScore, EM** ì„ í‰ê· í•´ `Final Mean`ì„ ë§Œë“¤ê³ , **ê°€ì¥ ë†’ì€ íŒŒì¼ì´ ê³§ Best Checkpoint**ë‹¤.

```bash
python evaluate_json.py   --input_dir outputs/infer_results/ \  # *.jsonë“¤ì´ ë“¤ì–´ìˆëŠ” í´ë”
  --label_path data/labels_eval.json
```

ì¶œë ¥ ì˜ˆì‹œ:

```
File: inference_epoch3.json
   - ROUGE-1        : 0.4132
   - BERTScore      : 0.6871
   - EM             : 0.5528
   - Final Mean     : 0.5510

Best Final Mean:
   File       : inference_epoch5.json
   Final Mean : 0.5742
```

---

## 7) ë§ˆë¬´ë¦¬

ê²°ë¡ ì ìœ¼ë¡œ í˜„ì¬ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì—ì„œ ì½œë°±ìœ¼ë¡œ **í•™ìŠµâ€‘ì €ì¥â€‘ê²€ì¦â€‘ì„ íƒ** ë£¨í”„ë¥¼ ìë™í™”í•˜ì—¬, ì‚¬ëŒ ì†ì„ ê±°ì˜ ì“°ì§€ ì•Šê³  **ê°€ì¥ ì¢‹ì€ ì²´í¬í¬ì¸íŠ¸**ë¥¼ ê³ ë¥¼ ìˆ˜ ìˆì—ˆë‹¤.

ë‹¤ìŒ í¸ì€ í•™ìŠµì„ ëŒë ¤ë³¸ ê²°ê³¼ì— ëŒ€í•´ ë‹¤ë¤„ë³¼ ì˜ˆì •ì´ë‹¤.
